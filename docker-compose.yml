services:
  api:
    container_name: LibreChat
    ports:
      - "${PORT}:${PORT}"
    depends_on:
      - mongodb
      - rag_api
      - redis
    image: localhost:5000/librechat:1.0.0
    restart: always
    user: "${UID}:${GID}"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - HOST=0.0.0.0
      - MONGO_URI=mongodb://mongodb:27017/LibreChat
      - MEILI_HOST=http://meilisearch:7700
      - RAG_PORT=${RAG_PORT:-8000}
      - RAG_API_URL=http://rag_api:${RAG_PORT:-8000}
    volumes:
      - type: bind
        source: ./.env
        target: /app/.env
        read_only: true
      - type: bind
        source: ./librechat.yaml
        target: /app/librechat.yaml
        read_only: true
      - ./data/images:/app/client/public/images
      - ./data/uploads:/app/uploads
      - ./data/logs:/app/api/logs

  mongodb:
    container_name: chat-mongodb
    image: localhost:5000/mongodb:1.0.0
    restart: always
    user: "${UID}:${GID}"
    volumes:
      - ./data/mongodb:/data/db
    command: mongod --noauth

  meilisearch:
    container_name: chat-meilisearch
    image: localhost:5000/meilisearch:1.0.0
    restart: always
    user: "${UID}:${GID}"
    environment:
      - MEILI_HOST=http://meilisearch:7700
      - MEILI_NO_ANALYTICS=true
      - MEILI_MASTER_KEY=${MEILI_MASTER_KEY}
    volumes:
      - ./data/meilisearch:/meili_data

  vectordb:
    container_name: vectordb
    image: localhost:5000/pgvectordb:1.0.0
    environment:
      POSTGRES_DB: mydatabase
      POSTGRES_USER: myuser
      POSTGRES_PASSWORD: mypassword
    restart: always
    user: "${UID}:${GID}"
    volumes:
      - ./data/pgvector:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  rag_api:
    container_name: rag_api
    image: localhost:5000/rag:1.0.0
    environment:
      - DB_HOST=vectordb
      - RAG_PORT=${RAG_PORT:-8000}
      - POSTGRES_DB=mydatabase
      - POSTGRES_USER=myuser
      - POSTGRES_PASSWORD=mypassword
    ports:
      - "${RAG_PORT:-8000}:${RAG_PORT:-8000}"
    restart: always
    user: "${UID}:${GID}"
    depends_on:
      - vectordb
    env_file:
      - .env

  ollama:
    container_name: ollama
    image: localhost:5000/ollama:1.0.0
    restart: always
    ports:
      - "11434:11434"
    user: "${UID}:${GID}"
    volumes:
      - ./data/ollama:/root/.ollama
    environment:
      - OLLAMA_NO_ANALYTICS=true
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  ollama-init:
    container_name: ollama-init
    image: localhost:5000/ollama:1.0.0
    restart: "no"
    user: "${UID}:${GID}"
    depends_on:
      - ollama
    volumes:
      - ./data/ollama:/root/.ollama
    environment:
      - OLLAMA_NO_ANALYTICS=true
      - OLLAMA_HOST=http://ollama:11434
    entrypoint: ["/bin/sh", "-c"]
    command: ["ollama pull tinyllama"]

  redis:
    container_name: chat-redis
    image: localhost:5000/redis:1.0.0
    restart: always
    user: "${UID}:${GID}"
    ports:
      - "6379:6379"
    volumes:
      - ./data/redis:/data
    command: redis-server --save 20 1 --loglevel warning --requirepass eYVX7EwVmmxKPCDmwMtyKVge8oLd2t81
